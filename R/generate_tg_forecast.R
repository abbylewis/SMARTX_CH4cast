source(here::here("R","run_all_sites.R"))
source(here::here("R","load_hist_weather.R"))
source(here::here("R","load_and_save_gefs.R"))
library(tidyverse)

generate_tg_forecast <- function(forecast_date,
                                 forecast_model,
                                 model_variables,
                                 model_id,
                                 model_timestep,
                                 all_sites = all_sites, #Whether the model is /trained/ across all sites
                                 sites = sites, #Sites to forecast
                                 noaa = T,
                                 save = T,
                                 plot = F,
                                 use_ref_year = T) {
  
  ### Step 1: Download latest target data
  target <- read_csv(here::here("L1_target.csv"))
  if(!use_ref_year){
    target <- target %>%
      filter(year(datetime) != 2021)
  }
  
  ### Step 2: Set forecast specifications
  if(sites == "all"){
    sites <- unique(target$site_id)
  }
  horiz = 35
  step = 1
  
  ### Step 3: Get NOAA driver data (if needed)
  if(noaa){ #Some forecasts do not use any noaa driver data --> in that case skip download
    forecast_date <- as.Date(forecast_date)
    
    #Identify available files
    saved_met <- list.files(here::here("met_downloads"))
    if(sum(grepl(forecast_date, saved_met)) == 0){
      #This function loads meteorology and harmonizes past/future predictions
      met <- load_and_save_gefs(date = forecast_date) 
      past <- load_hist_weather() #refresh historical data
    }

    #Load forecasts
    noaa_future_daily <- read_csv(here::here("met_downloads",
                                             paste0("future_daily_",forecast_date,".csv")),
                                  show_col_types = F) %>%
      pivot_wider(names_from = "variable", values_from = "prediction")
    
    # Load historical data
    noaa_past_mean <- read_csv(here::here("met_downloads",
                                         "past_daily_current.csv"),
                               show_col_types = F) %>%
      filter(datetime <= forecast_date) %>%
      pivot_wider(names_from = "variable", values_from = "prediction")
    
  } else {
    forecast_date <- as.Date(forecast_date)
    noaa_future_daily <- NULL
    noaa_past_mean <- NULL
  }
  
  ### Step 4: forecast!
  # Run all variables
  if(all_sites == F) {
    # Run all sites and depths individually for each variable
    forecast <- purrr::pmap(.l = list(model_variables),
                            .f = run_all_sites,
                            sites = sites,
                            forecast_model = forecast_model,
                            noaa_past_mean = noaa_past_mean,
                            noaa_future_daily = noaa_future_daily,
                            target = target,
                            horiz = horiz,
                            step = step,
                            forecast_date = forecast_date) %>%
      bind_rows()
  } else {
    # Fit model across all sites together for each variable
    forecast <- purrr::pmap(.l = list(model_variables),
                            .f = forecast_model,
                            sites = sites,
                            noaa_past_mean = noaa_past_mean,
                            noaa_future_daily = noaa_future_daily,
                            target = target,
                            horiz = horiz,
                            step = step,
                            forecast_date = forecast_date) %>%
      bind_rows()
  }
  
  if(nrow(forecast) == 0){
    stop("No forecast generated")
  }
  
  forecast <- forecast %>%
    mutate(model_id = model_id) %>%
    filter(datetime >= forecast_date)
  
  ### Step 5: Format and submit
  
  # Write forecast to disk
  if(save){
    forecast_file <- paste0(here::here("outputs", paste0("daily-", forecast_date, "-", model_id, ".csv.gz")))
    write_csv(forecast, forecast_file)
  }
  
  if(plot) {
    if(unique(forecast$family) == "ensemble"){
      p1 <- forecast %>%
        #mutate(site_id = factor(site_id, levels = chamber_levels)) %>%
        ggplot(aes(x = datetime, y = prediction)) +
        geom_hline(yintercept = 0, color = "grey50") +
        geom_vline(xintercept = forecast_date) +
        geom_line(aes(group = parameter), alpha = 0.3) +
        geom_point(data = target %>%
                     #mutate(site_id = factor(site_id, levels = chamber_levels)) %>%
                     filter(datetime >= forecast_date - 35 * step,
                            datetime <= forecast_date + horiz * step), 
                   aes(x = datetime, y = observation, alpha = datetime >= forecast_date)) +
        scale_alpha_manual(values = c(1, .5)) +
        theme(legend.position = "none")
      if(length(model_variables) == 1) {
        p1 <- p1 +
          facet_wrap(~site_id)
      } else {
        p1 <- p1 +
          facet_grid(rows = vars(variable), cols = vars(site_id))
      }
    } else {
      p1 <- forecast %>%
        #mutate(site_id = factor(site_id, levels = chamber_levels)) %>%
        pivot_wider(names_from = "parameter", values_from = "prediction") %>%
        ggplot(aes(x = datetime)) +
        geom_hline(yintercept = 0, color = "grey50") +
        geom_vline(xintercept = forecast_date) +
        geom_line(aes(y = mu)) +
        geom_ribbon(aes(ymin = mu - sigma, ymax = mu + sigma), alpha = 0.3) +
        geom_point(data = target %>%
                     #mutate(site_id = factor(site_id, levels = chamber_levels)) %>%
                     filter(datetime >= forecast_date - 35 * step,
                            datetime <= forecast_date + horiz * step), 
                   aes(x = datetime, y = observation, alpha = datetime >= forecast_date)) +
        scale_alpha_manual(values = c(1, .5)) +
        theme(legend.position = "none") +
        ylab("Flux (Âµmol/m2/day)")
      if(length(model_variables) == 1) {
        p1 <- p1 +
          facet_wrap(~site_id)
      } else {
        p1 <- p1 +
          facet_grid(rows = vars(variable), cols = vars(site_id))
      }
    }
    print(p1)
  }
}
